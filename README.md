#Glosario Big data

Glosario

|Concepto|¿Quién lo creo?|¿Cuándo?|Para qué sirve
|:---:   |:---:          |:---:   |:---:         

|hadoop|  el ingeniero de software Doug Cutting |2004| describe en un documento técnicas para manejar grandes volúmenes de datos, desgranándolos en problemas cada vez más pequeños para hacerlos abordables.
|ApacheFlume|||es un servicio distribuido, fiable, y altamente disponible para recopilar, agregar, y mover eficientemente grandes cantidades de datos.
|MapReduce |Yahoo|2008| es un modelo de programación para dar soporte a la computación paralela sobre grandes colecciones de datos en grupos de computadoras 
|Estructuradas|Edgar Frank Codd|década de los setenta|	Base de datos que se puede percibir como un conjunto de tablas y se puede manipular según el modelo relacional de los datos
|MongoDB |Geir Magnusson y Dwight Merriman.|11/02/2009|MongoDBes una base de datos orientada a documentos. Esto quiere decir que en lugar de guardar los datos en registros, guarda los datos en documentos. Estos documentos son almacenados en BSON, que es una representación binaria de JSON.

Docker||Solomon Hykes||23/07/2013||puede usar los contenedores como máquinas virtuales extremadamente livianas y modulares. Además, obtiene flexibilidad con estos contenedores: puede crearlos, implementarlos, copiarlos y moverlos de un entorno a otro, lo cual le permite optimizar sus aplicaciones para la nube.
apache spark||Universidad de Berkeley||2008 ||es un sistema de computación que se basa en Hadoop Map Reduce y que, principalmente, permite dividir o paralelizar el trabajo , ya que normalmente se instala en un clúster de máquina

